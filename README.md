# NeuralZOO

## 1] Introduction.

## 2] Veille technologique

### 2.1] Multilayer Perceptron

#### 2.1.1] Perceptron Multicouches, architectures & hyperparam√®tres  
Le Perceptron Multicouches (MLP) repr√©sente une √©volution significative dans le domaine des r√©seaux de neurones artificiels, marquant un progr√®s notable depuis les premiers mod√®les de perceptrons simples. D√©velopp√© dans les ann√©es 1980, le MLP a √©t√© con√ßu pour surmonter les limitations des perceptrons monocouches en introduisant des architectures plus complexes et des capacit√©s d'apprentissage plus profondes.  
Initialement inspir√© par les neurones biologiques et les premi√®res th√©ories du r√©seau neuronal formel, le concept de MLP a √©t√© formalis√© pour permettre l'apprentissage de mod√®les non lin√©aires gr√¢ce √† l'ajout de multiples couches de neurones. Cette approche a permis aux r√©seaux de neurones de traiter efficacement des probl√®mes de classification et de r√©gression complexes, en exploitant des fonctions d'activation non lin√©aires dans les couches cach√©es.  

Le MLP est un type de r√©seau de neurones artificiels compos√© de plusieurs couches:  
- Couches d'entr√©e  
- Couches cach√©es  
- Couches de sortie  
- Couches denses  

<u>Couches d'entr√©e:</u>  
Les couches d'entr√©e dans un MLP jouent un r√¥le crucial dans la r√©ception et la transmission des donn√©es initiales vers le r√©seau de neurones. Chaque neurone dans cette couche correspond √† une caract√©ristique sp√©cifique des donn√©es en entr√©e. Par exemple, dans le cas d'une t√¢che de classification d'images, chaque neurone pourrait repr√©senter les valeurs de pixels pour une zone particuli√®re de l'image. Les valeurs initiales sont propag√©es √† travers le r√©seau pour subir des transformations et des calculs ult√©rieurs.  

<u>Couches cach√©es:</u>  
Les couches cach√©es constituent le c≈ìur du MLP, o√π la majorit√© du traitement et de l'apprentissage se produisent. Chaque couche cach√©e est compos√©e de plusieurs neurones, chacun calculant une combinaison lin√©aire des sorties de la couche pr√©c√©dente, suivie d'une fonction d'activation non lin√©aire. Cela permet au r√©seau de capturer des motifs et des relations complexes dans les donn√©es, ce qui est crucial pour la capacit√© du mod√®le √† g√©n√©raliser √† de nouvelles observations. L'ajout de plusieurs couches cach√©es permet au MLP d'apprendre des repr√©sentations hi√©rarchiques et abstraites des donn√©es.  

<u>Couches de sortie:</u>  
Les couches de sortie dans un MLP produisent les pr√©dictions finales du mod√®le apr√®s avoir trait√© les informations √† travers les couches d'entr√©e et les couches cach√©es. Le nombre de neurones dans cette couche d√©pend de la nature sp√©cifique du probl√®me :  
- Pour une t√¢che de classification binaire, il y aurait un seul neurone avec une fonction d'activation comme sigmoid, indiquant la probabilit√© d'appartenir √† une classe.  
- Pour la classification multiclasse, il y aurait plusieurs neurones, un pour chaque classe, avec une activation comme softmax pour obtenir des probabilit√©s de classe.  
- Pour la r√©gression, il y aurait g√©n√©ralement un seul neurone produisant une valeur continue.  

<u>Couches denses:</u> 
Les couches denses dans un MLP, souvent appel√©es couches enti√®rement connect√©es, impliquent que chaque neurone est connect√© √† chaque neurone de la couche pr√©c√©dente et suivante. Cela cr√©e une structure de r√©seau dense o√π toutes les entr√©es sont connect√©es √† toutes les sorties, facilitant ainsi la propagation et le calcul efficaces des valeurs √† travers le r√©seau. Cette connectivit√© compl√®te permet au mod√®le d'apprendre des relations complexes entre les caract√©ristiques d'entr√©e et les cibles de sortie, tout en n√©cessitant un ajustement minutieux des poids et des biais pour optimiser les performances du mod√®le.  

En int√©grant ces diff√©rentes couches dans une architecture multicouche, le Perceptron Multicouches peut capturer des mod√®les non lin√©aires complexes dans les donn√©es, am√©liorant ainsi sa capacit√© √† r√©soudre une vari√©t√© de probl√®mes de machine learning. 

<u>**Les hyperparam√®tres**</u>
Les hyperparam√®tres jouent un r√¥le essentiel dans la conception et l'entra√Ænement des r√©seaux de neurones, y compris les Perceptrons Multicouches (MLP). Ce sont des param√®tres dont les valeurs sont fix√©es avant le d√©but du processus d'apprentissage et qui influencent directement la performance et la capacit√© du mod√®le √† apprendre et g√©n√©raliser √† de nouvelles donn√©es.

Choisir les bons hyperparam√®tres est crucial car ils d√©terminent la structure du r√©seau neuronal, la mani√®re dont il apprend √† partir des donn√©es, et la qualit√© des pr√©dictions qu'il produit. Par exemple, le nombre de couches cach√©es et le nombre de neurones par couche d√©finissent la complexit√© du mod√®le, tandis que le choix de la fonction d'activation et de la fonction de perte impacte la capacit√© du r√©seau √† mod√©liser des relations non lin√©aires et √† minimiser l'erreur de pr√©diction.  

Pour un MLP, les hyperparam√®tres cl√©s sont les suivants:  

**Fonction d'activation:** Elles introduisent de la non-lin√©arit√© dans le mod√®le, permettant au r√©seau de mod√©liser des relations non lin√©aires dans les donn√©es. Les choix courants incluent ReLU (Rectified Linear Unit), sigmoid, tanh, etc. ReLU est souvent pr√©f√©r√©e pour sa simplicit√© et sa performance dans de nombreux cas, mais le choix d√©pend du probl√®me sp√©cifique et de la nature des donn√©es.  

**Fonction de perte:** Elle mesure la diff√©rence entre les valeurs pr√©dites par le mod√®le et les valeurs r√©elles lors de l'entra√Ænement. Elle guide l'optimisation des poids du r√©seau pendant la r√©tropropagation. Pour diff√©rents types de t√¢ches (classification, r√©gression), des fonctions de perte sp√©cifiques comme la cross-entropy pour la classification ou le Mean Squared Error (MSE) pour la r√©gression sont utilis√©es.  

**Optimiseur:**  L'optimiseur est l'algorithme utilis√© pour ajuster les poids du r√©seau pendant la r√©tropropagation afin de minimiser la fonction de perte. Des optimiseurs populaires incluent Adam, SGD (Stochastic Gradient Descent), RMSProp, etc. Chacun a ses avantages en termes de vitesse de convergence, gestion du bruit, et adaptation du taux d'apprentissage.  

**Taux d'apprentissage (Learning Rate):** Il contr√¥le la taille des pas effectu√©s lors de l'optimisation des poids du r√©seau. Un taux d'apprentissage trop √©lev√© peut entra√Æner une divergence, tandis qu'un taux trop faible peut ralentir la convergence. Le r√©glage optimal du taux d'apprentissage est crucial pour un apprentissage efficace du mod√®le.  

**Batch Size:** Il d√©finit le nombre d'√©chantillons utilis√©s pour estimer le gradient des poids du r√©seau avant de mettre √† jour ces poids. Un batch size plus grand peut acc√©l√©rer le processus d'apprentissage en exploitant l'efficacit√© des calculs matriciels, tandis qu'un batch size plus petit peut fournir une estimation de gradient plus fr√©quente et potentiellement plus pr√©cise.  

**Nombre de couches cach√©es et de neurones par couche:** Le nombre de couches cach√©es et le nombre de neurones par couche d√©terminent la complexit√© et la capacit√© de repr√©sentation du r√©seau. Plus il y a de couches et de neurones, plus le mod√®le peut apprendre des repr√©sentations complexes des donn√©es. Cependant, trop de couches ou de neurones peuvent conduire √† un surapprentissage (overfitting).  

<u>**Fonctionnement du MLP**</u>  
Le Perceptron Multicouches fonctionne en deux phases principales :  
- la propagation avant (forward propagation) pour calculer les pr√©dictions  
- la r√©tropropagation (backpropagation) pour ajuster les poids du r√©seau en fonction de la fonction de perte.  

**Forward Propagation:**  
Lorsque des donn√©es sont introduites dans le r√©seau, elles traversent les diff√©rentes couches en commen√ßant par les couches d'entr√©e. Chaque neurone dans une couche cach√©e calcule une combinaison lin√©aire des activations de la couche pr√©c√©dente, suivie de l'application d'une fonction d'activation non lin√©aire comme ReLU, sigmoid ou tanh. Cette transformation se r√©p√®te √† travers chaque couche cach√©e jusqu'√† ce que les donn√©es atteignent la couche de sortie. Les neurones de la couche de sortie g√©n√®rent alors les pr√©dictions du mod√®le en fonction des activations finales des neurones pr√©c√©dents.  

**Backpropagation:**  
Une fois les pr√©dictions calcul√©es, le r√©seau compare ces pr√©dictions avec les valeurs r√©elles √† l'aide d'une fonction de perte sp√©cifique comme la cross-entropy pour la classification ou le MSE pour la r√©gression. Cette fonction de perte mesure la diff√©rence entre les pr√©dictions du mod√®le et les v√©rit√©s terrain.
En utilisant l'algorithme de r√©tropropagation, cette erreur est propag√©e de la couche de sortie vers les couches cach√©es, ajustant progressivement les poids du r√©seau pour minimiser la fonction de perte. Cela se fait en calculant les gradients des poids par rapport √† la fonction de perte √† l'aide de la d√©rivation chain√©e (chain rule).  

<u>**Exemple d'application:**</u> 
*- Classification d'Images* :  
Dans un probl√®me de classification d'images, un MLP pourrait prendre en entr√©e des images repr√©sent√©es par des pixels. Chaque neurone dans la couche d'entr√©e correspond √† un pixel. Les couches cach√©es du MLP apprennent √† extraire des caract√©ristiques hi√©rarchiques des images, comme les contours, les textures, et les formes.
La couche de sortie aurait un neurone par classe, activ√© par une fonction comme softmax pour pr√©dire la probabilit√© de chaque classe.  

*- R√©gression* :  
Pour une t√¢che de r√©gression, o√π l'objectif est de pr√©dire une valeur num√©rique, un MLP pourrait avoir une couche de sortie avec un seul neurone activ√© lin√©airement pour pr√©dire une valeur continue.
Les couches cach√©es permettent au r√©seau d'apprendre des relations complexes entre les variables d'entr√©e et la variable de sortie continue.  

En combinant propagation avant et r√©tropropagation, le Perceptron Multicouches est capable d'apprendre √† partir des donn√©es et d'ajuster ses param√®tres internes pour am√©liorer ses performances pr√©dictives.

#### 2.1.2] Choix d'architecture du PMC  
Le choix de l'architecture du Perceptron Multicouches, en fonction de la probl√©matique de classification ou de r√©gression, est crucial pour obtenir des r√©sultats optimaux et adapt√©s aux besoins sp√©cifiques de chaque type de t√¢che. Voici comment l'architecture est adapt√©e √† chacune de ces probl√©matiques :

<u>**Pour la Classification**</u>
Dans le contexte de la classification, o√π l'objectif est de pr√©dire une √©tiquette de classe pour chaque instance de donn√©es, l'architecture du PMC est g√©n√©ralement structur√©e de la mani√®re suivante :

*Couches d'Entr√©e* : Cette premi√®re couche re√ßoit les caract√©ristiques ou les variables des donn√©es d'entr√©e. Le nombre de neurones dans cette couche est d√©termin√© par le nombre de caract√©ristiques dans les donn√©es d'entr√©e.

*Couches Cach√©es* : Pour la classification, plusieurs couches cach√©es permettent au PMC d'apprendre des repr√©sentations hi√©rarchiques des donn√©es. Les choix typiques incluent l'utilisation de couches avec des fonctions d'activation non lin√©aires telles que ReLU, tanh, ou sigmoid. Plusieurs couches cach√©es permettent au mod√®le d'apprendre des caract√©ristiques abstraites et complexes des donn√©es, ce qui peut am√©liorer la capacit√© du mod√®le √† discriminer entre diff√©rentes classes.

*Couche de Sortie* : La derni√®re couche du PMC dans un probl√®me de classification est une couche de sortie compos√©e de neurones correspondant au nombre de classes √† pr√©dire. La fonction d'activation utilis√©e dans cette couche est g√©n√©ralement une softmax pour obtenir des probabilit√©s pour chaque classe. Cela permet de classifier chaque instance d'entr√©e dans l'une des classes pr√©d√©finies.

<u>**Pour la R√©gression**</u>  
En revanche, dans le cas de la r√©gression o√π l'objectif est de pr√©dire une valeur continue plut√¥t qu'une classe, l'architecture du PMC est ajust√©e de mani√®re l√©g√®rement diff√©rente :

*Couches d'Entr√©e* : Comme pour la classification, cette couche re√ßoit les caract√©ristiques des donn√©es d'entr√©e.

*Couches Cach√©es* : Les couches cach√©es sont √©galement utilis√©es pour apprendre des repr√©sentations complexes des donn√©es. Cependant, le nombre de couches et le nombre de neurones peuvent √™tre ajust√©s en fonction de la complexit√© des relations √† mod√©liser dans les donn√©es de r√©gression.

*Couche de Sortie* : Contrairement √† la classification, la couche de sortie dans la r√©gression est g√©n√©ralement compos√©e d'un seul neurone qui produit une valeur continue en sortie. La fonction d'activation dans cette couche est souvent lin√©aire ou une fonction identit√©, car elle permet de pr√©dire directement des valeurs num√©riques sans restriction de plage comme dans la classification.

En choisissant une architecture appropri√©e pour le Perceptron Multicouches en fonction de la classification ou de la r√©gression, on peut maximiser la capacit√© pr√©dictive du mod√®le tout en optimisant les ressources computationnelles et la complexit√© du r√©seau. Cette adaptation fine de l'architecture garantit que le mod√®le est bien adapt√© aux caract√©ristiques sp√©cifiques des donn√©es et aux exigences particuli√®res de chaque probl√®me de machine learning.

#### 2.1.3] D√©finitions  
**1. Fonction d'activation :**  
Une fonction d'activation est une fonction math√©matique appliqu√©e √† la sortie d'un neurone dans un r√©seau de neurones artificiels. Elle introduit de la non-lin√©arit√© dans le mod√®le, permettant ainsi au r√©seau de mod√©liser des relations complexes et non lin√©aires entre les variables d'entr√©e et de sortie.  
Voici quelques exemples de fonctions d'activation couramment utilis√©es :  

- ReLU (Rectified Linear Unit): ReLU($x$) = max(0, $x$)  
- Sigmoid: $\theta$($x$) = $\frac{1}{1+e^-x}$  
- Tanh (Tangente hyperbolique): tanh($x$) = $\frac {e^x - e^-x}{e^x + e^-x}$

**2. Forward Propagation :**  
La propagation avant est le processus par lequel les donn√©es sont introduites dans un r√©seau de neurones et propag√©es √† travers les diff√©rentes couches du r√©seau, de la couche d'entr√©e √† la couche de sortie. Chaque couche calcule une combinaison lin√©aire des entr√©es pond√©r√©es par les poids associ√©s √† chaque neurone, suivie de l'application d'une fonction d'activation.  

Exemple math√©matique (avec ReLU) : Pour une couche cach√©e : z = W x $x$ + b, a = ReLU($z$)  

$x$: Vecteur d'entr√©e  
$W$: Matrice de poids  
$b$: Vecteur de biais  
$z$: R√©sultat de la combinaison lin√©aire  
$a$: Activation apr√®s application de ReLU  

**3. Retropropagation :**  
La r√©tropropagation est l'algorithme utilis√© pour calculer le gradient de la fonction de perte par rapport aux poids du r√©seau, en partant de la couche de sortie et en remontant jusqu'√† la couche d'entr√©e. Cela permet de mettre √† jour les poids du r√©seau pour minimiser la fonction de perte, en utilisant des techniques d'optimisation telles que la descente de gradient.

Exemple conceptuel : Apr√®s avoir calcul√© l'erreur de pr√©diction √† partir de la fonction de perte, la r√©tropropagation ajuste les poids du r√©seau pour minimiser cette erreur en propageant le gradient de l'erreur de la sortie vers les couches pr√©c√©dentes.  

**4. Loss function :**  
La fonction de perte mesure la diff√©rence entre les pr√©dictions du mod√®le et les valeurs r√©elles attendues lors de l'entra√Ænement d'un r√©seau de neurones. Son objectif est de quantifier la performance du mod√®le et de guider l'algorithme d'optimisation (comme la descente de gradient) pour ajuster les poids du r√©seau.  

*Exemple*:  
Pour une t√¢che de classification binaire, une fonction de perte couramment utilis√©e est la Cross-Entropy Loss, d√©finie comme :  
Cross-Entropy Loss = 
$$
\sum_{i} y_i \log(p_i) + (1 - y_i) \log(1 - p_i)
$$

$y_{i}$ : Valeur r√©elle (0 ou 1)  
$p_{i}$ Probabilit√© pr√©dite pour la classe positive  

**5. Descente de Gradient (Gradient Descent) :**  
La descente de gradient est une technique d'optimisation utilis√©e pour minimiser la fonction de perte en ajustant it√©rativement les poids du r√©seau de neurones. Elle fonctionne en calculant le gradient de la fonction de perte par rapport aux poids du r√©seau, puis en ajustant les poids dans la direction oppos√©e du gradient.  

*Exemple*:  
Pour mettre √† jour les poids $ùëä$ d'une couche cach√©e dans un r√©seau de neurones en utilisant la descente de gradient, on utilise la r√®gle de mise √† jour :  
$$
W_{\text{new}} = W_{\text{old}} - \eta \cdot \nabla_{W} L
$$

$W_{new}$: Nouveaux poids apr√®s la mise √† jour   
$W_{old}$: Anciens poids  
$\eta$: taux d'apprentissage (learning rate), un hyperparam√®tre qui contr√¥le la taille des pas effectu√©s lors de la descente de gradient.  
$\nabla_{W} L$: Gradient du loss function $L$ par rapport aux poids $W$, indiquant la direction et l'amplitude du changement √† effectuer pour minimiser la perte $L$.  

**6. Vanishing Gradients**:  
Les gradients qui s'approchent de z√©ro de mani√®re exponentielle √† mesure que la profondeur du r√©seau augmente, posant ainsi des probl√®mes lors de l'entra√Ænement.


#### 2.1.4] Fonction d'activation

#### 2.1.5] D√©finition & diff√©renciation d'hyperparam√®tres

#### 2.1.6] Learning Rate

#### 2.1.7] Batch Normalization

#### 2.1.8] Algorithme d'Optimisation d'Adam

#### 2.1.9] D√©finir simplement le Perceptron Multicouches

### 2.2] Convolutional Neural Networs (CNN)

#### 2.2.1] R√©seaux de neurones artificiels de type convolutif

#### 2.2.2] Couche convolutive

#### 2.2.3] Quelle fonction d'activation pour CNN

#### 2.2.4] Feature Map

#### 2.2.5] Couche de Pooling

#### 2.2.6] Couche connect√©e

#### 2.2.7] Pourquoi pr√©f√©rer un R√©seau de neurones convolutifs √† un r√©seau dense pour une t√¢che de classification